<!DOCTYPE html>
<html>
<head>
	<title>David Lee | Unfinished projects</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link href="https://fonts.googleapis.com/css?family=Inconsolata|Spectral" rel="stylesheet">
	<style type="text/css">
		body {
			font-family: 'Spectral', serif;
		}

		a {
			/*color: #0000ff;*/
			color: inherit;
		}

		a:hover .sticker {
			box-shadow: 1px 1px 10px rgba(0, 0, 0, 0.3);
		}

		#main {
			margin: 20px;
			font-size: 16pt;
			line-height: 2;
			max-width: 600px;
		}

		.sticker {
			transition: box-shadow 0.2s;
			font-family: 'Inconsolata', monospace;
			box-shadow: 1px 1px 5px rgba(0, 0, 0, 0.3);
			padding: 3px;
			margin: 2px;
			border-radius: 5px;
		}

		#modal {
			position: fixed;
			left: 0;
			top: 0;
			width: 100vw;
			height: 100vh;

			display: flex;
			flex-flow: row nowrap;
			justify-content: center;
			align-items: center;
		}

		#modal #stage {
			display: flex;
			flex-flow: column nowrap;
			align-items: center;
		}

		#modal #stage img {
			max-width: 80%;
			max-height: 80%;
		}
	</style>
</head>
<body>
<div id="modal" style="visibility: hidden;" onclick="hideModal()">
	<div id="stage">
		<a class="close-button" href="#" onclick="hideModal(); return false;">close</a>
	</div>
</div>
<div id="main">
	<section id="tweener">
		<h2>
		let’s perform little emoji puppet shows!
		</h2>
		<h3>
		(what if the recordings were interactive?)
		</h3>
		<p>
		I wanted to make a tool to make interactive scenes, sort of like a choose your own adventure. I was interested in defining the scene as a tangle of animations between states, and using gestures to navigate and play those animations.
		</p>
		<p>
		In this app, the creator pulls emoji from a palette onto a canvas, and records a loop of animation by dragging the emoji around. The creator can then append a new animation onto the end of the current animation - when this animation finishes, the next one will play. This lets the creator sequence out a linear story.
		</p>
		<p>
		The creator can also add another animation alongside the current animation. When a viewer views the scene, they can choose which animation to follow. This lets the creator plot out branching paths in a story.
		</p>
		<p>
		i thought this was fun for a while, especially given how limited the emoji palette was. but I didn’t really like how separated all the animations were. yes, it was interactive; but the interactivity was just making a choice, triggering an animation, or scrubbing through an animation. It was point and click, and I’m tired of point and clicks. I wanted something more interactively “expressive,” which I felt couldn’t be created from a recording trapped in linear time.
		</p>
	</section>
	<section id="touchup">
		<h2>
			let’s mask and collage some images!
		</h2>
		<h3>
			(maybe videos too??)
		</h3>
		<p>
		I was thinking about making a video tool where the creator would usually start with a source image, masked and ready for composition. To help me out with making those masked images, and to learn more about Core Image, I made this little image editor. I was interested in making the app feel like you were working on and with something physical.
		</p>
		<p>
		In this app, a creator imports or takes a photo. the creator can pinch to resize or reposition the photo, or erase parts of the photo with the eraser tool. The creator can also tap the stamp button to “stamp” the photo to the background, allowing the creator to build up a collage of images by editing, stamping, editing, stamping, etc.
		</p>
		<p>
		some things I played around with here: 
		- the entire UI except for the buttons is done in Core Image. I don’t know if that was smart. but I learned a lot
		- you can do all of this stuff with videos as well (including stamping as a video and exporting as a video). it got a bit confusing with exporting / recording the correct thing, and with unsynced videos. but it's pretty cool.
		- made some buttons (the round ones) that smartly switch between quasimodal and modal - get the benefits of quasimodal if you’re into that, or have it work like you’d expect iOS buttons to work.
		- everything’s on a single screen, which led me to make a help overlay that just says what everything does on the screen. I was pretty into that.
		</p>
	</section>
	<section id="voodoo">
		<h2>
			let’s make videos by animating shaders!
		</h2>
		<h3>
			(on a phone???)
		</h3>
		<p>
		I wanted something like a musical instrument for my phone - something that I could just play with on the subway and entertainment myself with making stuff. Video seemed natural.
		</p>
		<p>
		this really was a natural next step after my emoji animation app. Instead of directly controlling an object’s position with a gesture, control parameters of “video effects” with gestures. some video effects I initially thought of were things like “open and close a gap in this image like a mouth”, “roll this image like a ball down a hill”, etc. - like Snapchat filters for motion. 
		</p>
		<p>
		with video effects like those, I could give up the object model of the emoji animation app. Instead, I could just apply a sequence of animated video effects to a source image, and get a flattened video. The sequencing of effects would, in a way, define ad-hoc objects within the image. I really liked this idea, since it keeps the user grounded in the world of the flattened image, instead of needing to manage many discrete objects (in the brains of the user and of the device).
		</p>
	</section>
	<section id="milkcrate">
		<h2>
			let’s use iOS 11 screen recording to bomb the music industry!
		</h2>
		<h3>
			(camera roll is a filesystem etc)
		</h3>
		<p>
		I realized that you can use iOS 11 screen recording to record audio off of Youtube. I used this to grab a bunch of sounds that I wanted to use, and added a feature to my video editor to import sounds from a video. then I could sample anything off of Youtube. isn’t that neat?
		</p>
		<p>
		it was kind of annoying, though. The thumbnails for all of my sound videos looked like the Spotify or Youtube interface (or worse, Control Center). I thought it would be nice if I could change the thumbnails so that I could browse my sounds from the camera roll, without having to tap into each one to figure out what that one is.
		</p>
		<p>
		so this is a utility app for doing, uh, that. import a video with some sound; put some text, maybe an image over it; export it back to your camera roll or whatever. use that nicely labeled sound video in some other app.
		</p>
		<p>
		(i mean, yeah, that’s the thing… hoping that other app developers will enable sound import from camera roll. an MPC app where you can sample anything off of Youtube? on your phone?? at ROSS???)
		</p>
	</section>
</div>

<script type="text/javascript">
	function presentImage(imagePath) {
		var stage = document.querySelector("#stage");
		var closeButton = document.querySelector("#stage .close-button");

		// Create image stage and add to DOM, above the close button.
		var img = document.createElement('img');
		stage.insertBefore(img, closeButton);

		// Set the image stage's image to the specified path.
		img.src = imagePath;

		// Show the modal.
		var modal = document.querySelector("#modal");
		modal.style['visibility'] = 'visible';
	}

	function hideModal() {
		// Remove image stage from DOM.
		var imageStage = document.querySelector("#modal img");
		imageStage.parentElement.removeChild(imageStage);

		// Hide the modal.
		var modal = document.querySelector("#modal");
		modal.style['visibility'] = 'hidden';
	}
</script>
</body>
</html>
